{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1 - Page Rank\n",
    "\n",
    "## Première partie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def square_elements():\n",
    "    L=np.array([1,2,3,4,5])\n",
    "    M=L*L\n",
    "    return (L,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5]), array([ 1,  4,  9, 16, 25]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_integer(L):\n",
    "    M=[]\n",
    "    for i in L:\n",
    "        if i%2==0:\n",
    "            M.append(i)\n",
    "    return (L,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([7, 6198, 61, 88, 9, 1, 2], [6198, 88, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_integer([7,6198,61,88,9,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(file):\n",
    "    f=open(file,\"r\")\n",
    "    L=[]\n",
    "    for line in f:\n",
    "        u=[int(x) for x in line.split()]\n",
    "        L.append(u)\n",
    "    return even_integer(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deuxième partie :\n",
    "    \n",
    "### Question 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def norme_un(A,B):                  #calculate the norm of the diffrence between two column vectors\n",
    "    norme = 0\n",
    "    for i in range(0,len(A)):\n",
    "        norme+=abs(A[i]-B[i])\n",
    "    return norme\n",
    "\n",
    "def multiply_sparse(matrix,vector): #product of a sparse matrix by a column vector\n",
    "    new_vector = [0 for i in range(len(vector))]\n",
    "    for line in matrix:\n",
    "        u,v,coeff=line[0],line[1],line[2]\n",
    "        new_vector[u-1] += coeff*vector[v-1]\n",
    "    return np.array(new_vector)\n",
    "\n",
    "def file_to_graph(file):            #convert a file into a directed graph\n",
    "    f=open(file,'r')\n",
    "    graph = []\n",
    "    for line in f : \n",
    "        u,v = [int(x) for x in line.split()]\n",
    "        graph.append([u,v])         #each element is a list [i, j] denoting that there is an edge between node i and j\n",
    "    return graph\n",
    "\n",
    "def PageRank(graph, beta, eps):\n",
    "    G,M=graph,[]\n",
    "    n=0\n",
    "    dico={}\n",
    "    for edge in G : \n",
    "        compteur=0               \n",
    "        u,v=edge[0],edge[1]\n",
    "        for edge in G:              #we count the number of edges going from node u in order to have the right ponderations in the M matrix\n",
    "            if edge[0]==u:       \n",
    "                compteur+=1\n",
    "        M.append([v,u,1/compteur])  #creation of the M matrix\n",
    "        if u>n:                     #we search the maximum of G, corresponding to the number of nodes\n",
    "            n=u\n",
    "        elif v>n:\n",
    "            n=v   \n",
    "    pi=[1.0 for i in range (0,n)]   #creation of the PageRank Vector\n",
    "    pi=np.array(pi)*1/n\n",
    "    B=(1-beta)*pi\n",
    "    new_pi=beta*multiply_sparse(M,pi)+B\n",
    "    while (norme_un(new_pi,pi)>=eps) :\n",
    "        pi = new_pi\n",
    "        new_pi=beta*multiply_sparse(M,new_pi)+B\n",
    "    return new_pi\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our algorithm with different values for beta :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27083333, 0.13541667, 0.15625   , 0.14583333, 0.13541667,\n",
       "       0.15625   ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PageRank(file_to_graph(\"graphe.txt\"),1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25733333, 0.13626667, 0.156     , 0.15813333, 0.13626667,\n",
       "       0.156     ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PageRank(file_to_graph(\"graphe.txt\"),0.8,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from os import listdir\n",
    "import html\n",
    "\n",
    "directory = listdir('./toyset/')\n",
    "data={}\n",
    "page_nb = 0\n",
    "for page in directory :\n",
    "    with open('./toyset/'+page, 'r') as file : #create a dictionnary with the number of each page and its content\n",
    "        page_nb+=1\n",
    "        data[page]=(page_nb, file.read())\n",
    "\n",
    "graph_G = []\n",
    "for linkName,content in data.items():\n",
    "    linksList = re.findall(r'href=[\\'\"]?([^\\'\">]+)', content[1]) \n",
    "    for link in linksList :\n",
    "        if link in data.keys():\n",
    "            pageNumber = content[0]\n",
    "            link_L = data[link][0]\n",
    "            if linkName!=link and (pageNumber, link_L) not in graph_G: #adds an edge to the graph between the page and the link it cites\n",
    "                graph_G.append([pageNumber, link_L])\n",
    "\n",
    "graph = open('webgraph.txt', 'w')\n",
    "for i,j in graph_G:\n",
    "    graph.write(str(i) + \" \" + str(j) + \"\\n\")\n",
    "graph.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary_file.html : 0.00216593658823958\n",
      "Object-oriented_programming.html : 0.03324846793989462\n",
      "Imperative_programming.html : 0.023473028617973235\n",
      "Boolean_data_type.html : 0.007078745509768735\n",
      "Memory_address.html : 0.007327024291781016\n",
      "Subroutine.html : 0.014395521162311221\n",
      "Lisp_(programming_language).html : 0.024468745198547536\n",
      "C_(programming_language).html : 0.07465733642733272\n",
      "Computer_memory.html : 0.008600458410260683\n",
      "Virtual_machine.html : 0.01696999394345276\n",
      "Software.html : 0.011142079478703932\n",
      "Computer_science.html : 0.014915684698885124\n",
      "Unix.html : 0.019496252317822135\n",
      "Operating_system.html : 0.03694632890068564\n",
      "Porting.html : 0.00697142994569998\n",
      "Type_system.html : 0.023264456889537037\n",
      "Lexical_scope.html : 0.0008434688327253301\n",
      "Source_code.html : 0.017643386479138698\n",
      "Program_(machine).html : 0.0005407275765398125\n",
      "Pointer_(computer_programming).html : 0.014574479395782958\n",
      "High-level_programming_language.html : 0.020100123302945565\n",
      "JavaScript.html : 0.026407161898166085\n",
      "Database.html : 0.005846216111117379\n",
      "Assembly_language.html : 0.04220240027078291\n",
      "Computer_hardware.html : 0.017476883825672355\n",
      "Software_portability.html : 0.007504621627168926\n",
      "Snowball_programming_language.html : 0.00141011857158152\n",
      "Computer.html : 0.013603968023734234\n",
      "List_of_programming_languages.html : 0.017918344784061867\n",
      "Python_(programming_language).html : 0.03852120251046344\n",
      "Control_flow.html : 0.007021100293219772\n",
      "Low-level_programming_language.html : 0.011265783901277339\n",
      "Compiler.html : 0.04128134002038835\n",
      "GNU_Compiler_Collection.html : 0.017194481472263157\n",
      "Java_(programming_language).html : 0.05022622229647711\n",
      "Computer_program.html : 0.016063171531422796\n",
      "Logic_programming.html : 0.009117262293388499\n",
      "Integer_(computer_science).html : 0.007253367189263636\n",
      "Executable.html : 0.01010511317500049\n",
      "COBOL.html : 0.019499343868763536\n",
      "Kernel_(computing).html : 0.004105940077611716\n",
      "Linux.html : 0.021836865233971568\n",
      "Fortran.html : 0.025261720291153724\n",
      "Dynamic_programming_language.html : 0.01019250888839219\n",
      "Instruction_set.html : 0.011979855730830496\n",
      "C++.html : 0.05040311801379968\n",
      "Data_type.html : 0.01618807051077937\n",
      "Programming_language.html : 0.05378724304246833\n",
      "Strong_and_weak_typing.html : 0.0032035213109836112\n",
      "Bytecode.html : 0.0121489329558852\n",
      "Object_(computer_science).html : 0.013963289381296895\n",
      "Method_(computer_programming).html : 0.0031709449906841877\n",
      "Data_(computing).html : 0.0060010846909838034\n",
      "Scripting_language.html : 0.011885277331533354\n",
      "Comparison_of_programming_languages.html : 0.017129847977384108\n"
     ]
    }
   ],
   "source": [
    "my_graph=PageRank(file_to_graph(\"webgraph.txt\"),1,0.1)\n",
    "\n",
    "for pageName, index in data.items():\n",
    "    print(pageName, \":\", str(my_graph[index[0]-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_dead_end(G,x,n):\n",
    "    for line in range(len(G)) :        #search if the node x has an out-link\n",
    "        if G[line][0]==x :\n",
    "            return G, n\n",
    "    for line in range(len(G)-1,0,-1) : #all the links to x are removed\n",
    "        if G[line][1]==x:\n",
    "            G.remove(G[line])\n",
    "    return G, n-1                      #we have removed a node\n",
    "\n",
    "def remove_dead_ends(G):\n",
    "    n=0\n",
    "    for nodes in G:\n",
    "        for i in nodes:\n",
    "            if i>n:\n",
    "                n=i                    #search of the number of nodes in G\n",
    "    old_n=n\n",
    "    for i in range (n,0,-1):           #we start from the end to avoid problems with the number of nodes\n",
    "        G, n = is_dead_end(G,i,n)\n",
    "    if old_n==n:                       #check if the number of nodes has changed : if not, all the dead-ends have been removed !\n",
    "        return G\n",
    "    return remove_dead_ends(G)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our fuction with an example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [2, 3], [3, 4], [4, 1], [1, 5], [5, 1]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_dead_ends([[1,2],[2,3],[4,7],[3,4],[7,6],[4,1],[1,5],[5,6],[5,1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
